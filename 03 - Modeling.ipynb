{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d9affe",
   "metadata": {},
   "source": [
    "## Data Modeling\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1506631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T13:51:35.446560Z",
     "start_time": "2023-08-25T13:51:33.597045Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, recall_score, log_loss, roc_auc_score, make_scorer, fbeta_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV, train_test_split, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, recall_score, log_loss, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV, train_test_split, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_csv('data/Cardiovascular_Diseases_Risk_Prediction_Dataset.csv')\n",
    "ordinal = ['General_Health', 'Checkup', 'Age_Category']\n",
    "numeric = list(df.select_dtypes(exclude=object).columns)\n",
    "categorical = list(df.select_dtypes(object).columns)\n",
    "for i in ordinal:\n",
    "    categorical.remove(i)\n",
    "categorical.remove('Heart_Disease')\n",
    "\n",
    "# Splitting the training from the validation data\n",
    "# Making sure the split is stratefied given teh imbalance of our target variable\n",
    "y = df['Heart_Disease']\n",
    "X = df.drop('Heart_Disease',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=12, stratify= y)\n",
    "\n",
    "# Transforming the target variable into 1's and 0's\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "\n",
    "# Listing categories in order for each ordinal variable.\n",
    "health = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "check = [\n",
    "    'Never', '5 or more years ago', 'Within the past 5 years',\n",
    "    'Within the past 2 years', 'Within the past year'\n",
    "]\n",
    "age = [\n",
    "    '18-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59',\n",
    "    '60-64', '65-69', '70-74', '75-79', '80+'\n",
    "]\n",
    "\n",
    "# Instantiating an OrdinalEncoder transformer to encode ordinal variables. \n",
    "oe = OrdinalEncoder(categories=[health, check, age])\n",
    "\n",
    "\n",
    "# Instantiating a OneHotEncoder transformer to be used on the categorical varaibles. \n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# Creating a column transformer to be used in a pipeline\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('oe', OrdinalEncoder(categories=[health, check, age]), ordinal),\n",
    "    ('ohe', OneHotEncoder(), categorical)\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "def model_scores(model_name, model, X_train, y_train, model_list= [], notes = ''):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\n",
    "    scoring = {'f2': make_scorer(fbeta_score, beta=2),\n",
    "               'recall': 'recall',\n",
    "               'accuracy':'accuracy',\n",
    "               'f1':'f1',\n",
    "               'roc_auc':'roc_auc',\n",
    "               'precision': 'precision'}\n",
    "    scores = cross_validate(model,\n",
    "                           X_train,\n",
    "                           y_train,\n",
    "                           scoring = scoring,\n",
    "                           cv=skf,\n",
    "                           n_jobs=-1)\n",
    "    time = round(scores['fit_time'].mean() + scores['score_time'].mean(),0)\n",
    "    f2 = round(scores['test_f2'].mean(),4)*100\n",
    "    recall = round(scores['test_recall'].mean(),4)*100\n",
    "    accuracy = round(scores['test_accuracy'].mean(),4)*100\n",
    "    f1 = round(scores['test_f1'].mean(),4)*100\n",
    "    roc_auc = round(scores['test_roc_auc'].mean(),4)*100\n",
    "    precision = round(scores['test_precision'].mean(),4)*100\n",
    "    model_list.append([model_name, time, f2, recall, accuracy, f1, roc_auc, precision, notes])\n",
    "    df = pd.DataFrame(model_list, columns=['model', 'time (in s)', 'f2', 'recall', 'accuracy', 'f1', 'roc_auc', 'precision', 'notes'])\n",
    "    return model_list, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f854fc",
   "metadata": {},
   "source": [
    "### Dummy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51e70b82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T13:57:29.391747Z",
     "start_time": "2023-08-25T13:57:27.295282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time (in s)</th>\n",
       "      <th>f2</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dummy Model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  time (in s)   f2  recall  accuracy   f1  roc_auc  \\\n",
       "0  DummyClassifier          1.0  0.0     0.0     91.92  0.0     50.0   \n",
       "\n",
       "   precision        notes  \n",
       "0        0.0  Dummy Model  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('ct', col_transformer),\n",
    "                      ('dm', DummyClassifier(strategy='most_frequent'))])\n",
    "dummy_model = pipe.fit(X_train, y_train)\n",
    "ml1, df1 = model_scores('DummyClassifier', dummy_model, X_train, y_train, model_list= [], notes= \"Dummy Model\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016bc88",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8793e75a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T13:57:32.595789Z",
     "start_time": "2023-08-25T13:57:29.393645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time (in s)</th>\n",
       "      <th>f2</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Dummy Model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.18</td>\n",
       "      <td>91.94</td>\n",
       "      <td>11.03</td>\n",
       "      <td>83.41</td>\n",
       "      <td>51.39</td>\n",
       "      <td>Baseline Model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  time (in s)   f2  recall  accuracy     f1  roc_auc  \\\n",
       "0     DummyClassifier          1.0  0.0    0.00     91.92   0.00    50.00   \n",
       "1  LogisticRegression          2.0  7.5    6.18     91.94  11.03    83.41   \n",
       "\n",
       "   precision           notes  \n",
       "0       0.00     Dummy Model  \n",
       "1      51.39  Baseline Model  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('ct', col_transformer),\n",
    "                       ('ss', StandardScaler()),\n",
    "                      ('log_reg', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=12))])\n",
    "logreg_model = pipe.fit(X_train, y_train)\n",
    "ml2, df2 = model_scores('LogisticRegression', logreg_model, X_train, y_train, model_list= ml1, notes= \"Baseline Model\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d845e24a",
   "metadata": {},
   "source": [
    "### Model Iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e39ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'xbg__reg_lambda': 1, 'xbg__reg_alpha': 1, 'xbg__n_estimators': 250, 'xbg__min_child_weight': 7, 'xbg__max_depth': 3, 'xbg__gamma': 0.1, 'xbg__eta': 0.15, 'xbg__colsample_bytree': 0.26530612244897955}\n",
    "{'xbg__reg_lambda': 10, 'xbg__reg_alpha': 0.01, 'xbg__n_estimators': 500, 'xbg__min_child_weight': 3, 'xbg__max_depth': 14, 'xbg__gamma': 0.1, 'xbg__eta': 0.01, 'xbg__colsample_bytree': 0.5306122448979591}\n",
    "{'xbg__reg_lambda': 1, 'xbg__reg_alpha': 10, 'xbg__n_estimators': 650, 'xbg__min_child_weight': 9, 'xbg__max_depth': 3, 'xbg__gamma': 10, 'xbg__eta': 0.05, 'xbg__colsample_bytree': 0.8775510204081632}\n",
    "{'xbg__reg_lambda': 0, 'xbg__reg_alpha': 0.01, 'xbg__n_estimators': 800, 'xbg__min_child_weight': 4, 'xbg__max_depth': 1, 'xbg__gamma': 10, 'xbg__eta': 0.001, 'xbg__colsample_bytree': 0.8163265306122448}\n",
    "{'xbg__reg_lambda': 1, 'xbg__reg_alpha': 0, 'xbg__n_estimators': 550, 'xbg__min_child_weight': 8, 'xbg__max_depth': 9, 'xbg__gamma': 0, 'xbg__eta': 0.3, 'xbg__colsample_bytree': 0.5102040816326531}\n",
    "{'xbg__reg_lambda': 1, 'xbg__reg_alpha': 0, 'xbg__n_estimators': 550, 'xbg__min_child_weight': 8, 'xbg__max_depth': 9, 'xbg__gamma': 0, 'xbg__eta': 0.3, 'xbg__colsample_bytree': 0.5102040816326531}\n",
    "{'xbg__reg_lambda': 1, 'xbg__reg_alpha': 1, 'xbg__n_estimators': 250, 'xbg__min_child_weight': 7, 'xbg__max_depth': 3, 'xbg__gamma': 0.1, 'xbg__eta': 0.15, 'xbg__colsample_bytree': 0.26530612244897955}\n",
    "{'xbg__reg_lambda': 1, 'xbg__reg_alpha': 0, 'xbg__n_estimators': 550, 'xbg__min_child_weight': 8, 'xbg__max_depth': 9, 'xbg__gamma': 0, 'xbg__eta': 0.3, 'xbg__colsample_bytree': 0.5102040816326531}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f00468b",
   "metadata": {},
   "source": [
    "### Final Model\n",
    "I decided to have my final model be the step where `greenbelt` was dropped (index = 8) because the the Adjusted R-Squared was high, the Mean Absolute Error was relatively low, and the Conditional Number didn't seem to improve much as the iteration continued. \n",
    "\n",
    "**Target Variable:** price <br>\n",
    "**Predictor Variables:** sqft_living_norm, waterfront, and 65 different zip codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb6b17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T16:08:19.879188Z",
     "start_time": "2023-07-03T16:08:19.434986Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This function does the same thing as baseline, but for the final model.\n",
    "final_results, final_df = dm.final_res(df)\n",
    "final_df\n",
    "\n",
    "# I still wonder if 68 features is too many, perhaps this is why the condition \n",
    "# number is still so large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2befe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
