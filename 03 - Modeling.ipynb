{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "1. Dummy\n",
    "2. Logreg\n",
    "\n",
    "XGBClassifier, RandomForest\n",
    "\n",
    "3. XGBClassifier, f2\n",
    "3. XGBClassifier, f2-weighted\n",
    "3. XGBClassifier, f2-SMOTE\n",
    "3. XGBClassifier, f2-ADASYN\n",
    "\n",
    "Randomize winner?\n",
    "\n",
    "Gridsearch from there?\n",
    "\n",
    "3. XGBClassifier, f2 - randomizedcv\n",
    "3. XGBClassifier, f2-weighted - randomizedcv\n",
    "3. XGBClassifier, f2-SMOTE - randomizedcv\n",
    "3. XGBClassifier, f2, randomizedcv\n",
    "3. XGBClassifier, f2-weighted, randomizedcv\n",
    "3. XGBClassifier, f2, randomizedcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:23:16.485906Z",
     "start_time": "2023-08-26T17:23:15.152825Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, recall_score, log_loss, roc_auc_score, make_scorer, fbeta_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV, train_test_split, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, recall_score, log_loss, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV, train_test_split, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_csv('data/Cardiovascular_Diseases_Risk_Prediction_Dataset.csv')\n",
    "ordinal = ['General_Health', 'Checkup', 'Age_Category']\n",
    "numeric = list(df.select_dtypes(exclude=object).columns)\n",
    "categorical = list(df.select_dtypes(object).columns)\n",
    "for i in ordinal:\n",
    "    categorical.remove(i)\n",
    "categorical.remove('Heart_Disease')\n",
    "\n",
    "# Splitting the training from the validation data\n",
    "# Making sure the split is stratefied given teh imbalance of our target variable\n",
    "y = df['Heart_Disease']\n",
    "X = df.drop('Heart_Disease',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=12, stratify= y)\n",
    "\n",
    "# Transforming the target variable into 1's and 0's\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "\n",
    "# Listing categories in order for each ordinal variable.\n",
    "health = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "check = [\n",
    "    'Never', '5 or more years ago', 'Within the past 5 years',\n",
    "    'Within the past 2 years', 'Within the past year'\n",
    "]\n",
    "age = [\n",
    "    '18-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59',\n",
    "    '60-64', '65-69', '70-74', '75-79', '80+'\n",
    "]\n",
    "\n",
    "# Instantiating an OrdinalEncoder transformer to encode ordinal variables. \n",
    "oe = OrdinalEncoder(categories=[health, check, age])\n",
    "\n",
    "\n",
    "# Instantiating a OneHotEncoder transformer to be used on the categorical varaibles. \n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# Creating a column transformer to be used in a pipeline\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('oe', OrdinalEncoder(categories=[health, check, age]), ordinal),\n",
    "    ('ohe', OneHotEncoder(), categorical)\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "def model_scores(model_name, model, X_train, y_train, model_list= [], notes = ''):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\n",
    "    scoring = {'f2': make_scorer(fbeta_score, beta=2),\n",
    "               'recall': 'recall',\n",
    "               'accuracy':'accuracy',\n",
    "               'f1':'f1',\n",
    "               'roc_auc':'roc_auc',\n",
    "               'precision': 'precision'}\n",
    "    scores = cross_validate(model,\n",
    "                           X_train,\n",
    "                           y_train,\n",
    "                           scoring = scoring,\n",
    "                           cv=skf,\n",
    "                           n_jobs=-1)\n",
    "    time = round(scores['fit_time'].mean() + scores['score_time'].mean(),0)\n",
    "    f2 = round(scores['test_f2'].mean(),4)*100\n",
    "    recall = round(scores['test_recall'].mean(),4)*100\n",
    "    accuracy = round(scores['test_accuracy'].mean(),4)*100\n",
    "    f1 = round(scores['test_f1'].mean(),4)*100\n",
    "    roc_auc = round(scores['test_roc_auc'].mean(),4)*100\n",
    "    precision = round(scores['test_precision'].mean(),4)*100\n",
    "    model_list.append([model_name, time, f2, recall, accuracy, f1, roc_auc, precision, notes])\n",
    "    df = pd.DataFrame(model_list, columns=['model', 'time (in s)', 'f2', 'recall', 'accuracy', 'f1', 'roc_auc', 'precision', 'notes'])\n",
    "    return model_list, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T16:17:28.294442Z",
     "start_time": "2023-08-26T16:17:24.353196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time (in s)</th>\n",
       "      <th>f2</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dummy Model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  time (in s)   f2  recall  accuracy   f1  roc_auc  \\\n",
       "0  DummyClassifier          1.0  0.0     0.0     91.92  0.0     50.0   \n",
       "\n",
       "   precision        notes  \n",
       "0        0.0  Dummy Model  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('ct', col_transformer),\n",
    "                      ('dm', DummyClassifier(strategy='most_frequent'))])\n",
    "dummy_model = pipe.fit(X_train, y_train)\n",
    "ml, df1 = model_scores('DummyClassifier', dummy_model, X_train, y_train, model_list= [], notes= \"Dummy Model\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T16:17:35.804697Z",
     "start_time": "2023-08-26T16:17:30.930926Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('ct', col_transformer),\n",
    "                       ('ss', StandardScaler()),\n",
    "                      ('log_reg', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=12))])\n",
    "logreg_model = pipe.fit(X_train, y_train)\n",
    "ml, df1 = model_scores('LogisticRegression', logreg_model, X_train, y_train, model_list= ml, notes= \"Baseline Model\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:03:09.055156Z",
     "start_time": "2023-08-26T17:01:55.938675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time (in s)</th>\n",
       "      <th>f2</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.34</td>\n",
       "      <td>4.38</td>\n",
       "      <td>91.81</td>\n",
       "      <td>7.96</td>\n",
       "      <td>80.85</td>\n",
       "      <td>43.76</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.22</td>\n",
       "      <td>5.10</td>\n",
       "      <td>91.89</td>\n",
       "      <td>9.23</td>\n",
       "      <td>82.99</td>\n",
       "      <td>48.57</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  time (in s)    f2  recall  accuracy    f1  roc_auc  \\\n",
       "0  RandomForestClassifier         40.0  5.34    4.38     91.81  7.96    80.85   \n",
       "1           XGBClassifier         58.0  6.22    5.10     91.89  9.23    82.99   \n",
       "\n",
       "   precision  notes  \n",
       "0      43.76  Basic  \n",
       "1      48.57  Basic  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rfc = Pipeline(steps=[('ct', col_transformer),\n",
    "                       ('rfc', RandomForestClassifier(random_state=12))])\n",
    "rfc_model = pipe_rfc.fit(X_train, y_train)\n",
    "compare_list, compare_df = model_scores('RandomForestClassifier', rfc_model, X_train, y_train, model_list= [] notes= \"Basic\")\n",
    "\n",
    "pipe_xgb = Pipeline(steps=[('ct', col_transformer),\n",
    "                       ('xgb', XGBClassifier(random_state=12))])\n",
    "xgb_model = pipe_xgb.fit(X_train, y_train)\n",
    "compare_list, compare_df = model_scores('XGBClassifier', xgb_model, X_train, y_train, model_list= compare_list notes= \"Basic\")\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:38:38.728829Z",
     "start_time": "2023-08-26T17:23:26.530122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time (in s)</th>\n",
       "      <th>f2</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>53.0</td>\n",
       "      <td>49.27</td>\n",
       "      <td>75.49</td>\n",
       "      <td>74.52</td>\n",
       "      <td>32.39</td>\n",
       "      <td>82.41</td>\n",
       "      <td>20.62</td>\n",
       "      <td>Weighted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>144.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>5.57</td>\n",
       "      <td>91.81</td>\n",
       "      <td>9.90</td>\n",
       "      <td>82.81</td>\n",
       "      <td>44.54</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>336.0</td>\n",
       "      <td>6.34</td>\n",
       "      <td>5.22</td>\n",
       "      <td>91.83</td>\n",
       "      <td>9.36</td>\n",
       "      <td>82.86</td>\n",
       "      <td>45.48</td>\n",
       "      <td>ADASYN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  time (in s)     f2  recall  accuracy     f1  roc_auc  \\\n",
       "0  XGBClassifier         53.0  49.27   75.49     74.52  32.39    82.41   \n",
       "1  XGBClassifier        144.0   6.75    5.57     91.81   9.90    82.81   \n",
       "2  XGBClassifier        336.0   6.34    5.22     91.83   9.36    82.86   \n",
       "\n",
       "   precision     notes  \n",
       "0      20.62  Weighted  \n",
       "1      44.54     SMOTE  \n",
       "2      45.48    ADASYN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose between XGBClassifier Variants\n",
    "\n",
    "# Basic\n",
    "ml_xgb, df_xgb = model_scores('XGBClassifier', xgb_model, X_train, y_train, model_list = [], notes= \"Basic\")\n",
    "\n",
    "# Weighted\n",
    "pipe = Pipeline(steps=[('ct', col_transformer),\n",
    "                       ('xgb', XGBClassifier(random_state=12,scale_pos_weight=283883/24971))])\n",
    "xgb_weighted = pipe.fit(X_train, y_train)\n",
    "ml_xgb, df_xgb = model_scores('XGBClassifier', xgb_weighted, X_train, y_train, model_list = ml_xgb, notes= \"Weighted\")\n",
    "\n",
    "# SMOTE\n",
    "pipe = ImPipeline(steps=[('ct', col_transformer),\n",
    "                       ('ss', StandardScaler()),\n",
    "                       ('sm',SMOTE(random_state=12)),\n",
    "                       ('xgb', XGBClassifier(random_state=12))])\n",
    "xgb_smote = pipe.fit(X_train, y_train)\n",
    "ml_xgb, df_xgb = model_scores('XGBClassifier', xgb_smote, X_train, y_train, model_list = ml_xgb, notes= \"SMOTE\")\n",
    "\n",
    "# ADASYN\n",
    "pipe = ImPipeline(steps=[('ct', col_transformer),\n",
    "                       ('ss', StandardScaler()),\n",
    "                       ('sm',ADASYN(random_state=12)),\n",
    "                       ('xgb', XGBClassifier(random_state=12))])\n",
    "xgb_adasyn = pipe.fit(X_train, y_train)\n",
    "ml_xgb, df_xgb = model_scores('XGBClassifier', xgb_adasyn, X_train, y_train, model_list = ml_xgb, notes= \"ADASYN\")\n",
    "df_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T17:43:53.784887Z",
     "start_time": "2023-08-26T17:43:41.794345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time (in s)</th>\n",
       "      <th>f2</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.38</td>\n",
       "      <td>5.24</td>\n",
       "      <td>91.86</td>\n",
       "      <td>9.43</td>\n",
       "      <td>82.94</td>\n",
       "      <td>46.74</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  time (in s)    f2  recall  accuracy    f1  roc_auc  \\\n",
       "0  XGBClassifier          7.0  6.38    5.24     91.86  9.43    82.94   \n",
       "\n",
       "   precision  notes  \n",
       "0      46.74  Basic  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_xgb = Pipeline(steps=[('ct', col_transformer),\n",
    "                       ('xgb', XGBClassifier(random_state=12, tree_method='hist'))])\n",
    "xgb_model = pipe_xgb.fit(X_train, y_train)\n",
    "blah, duh = model_scores('XGBClassifier', xgb_model, X_train, y_train, model_list= [], notes= \"Basic\")\n",
    "duh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the Weighted\n",
    "pipe = Pipeline(steps=[('ct', col_transformer),\n",
    "                       ('xbg', XGBClassifier(random_state=12, tree_method='hist', scale_pos_weight= 283883/24971))])\n",
    "\n",
    "params = {\n",
    "    'xbg__n_estimators': range(50,1000,50),\n",
    "    'xbg__max_depth': range(1,15),\n",
    "    'xbg__eta': [0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "    'xbg__colsample_bytree': np.linspace(0,1,50),\n",
    "    'xbg__min_child_weight': range(1,10),\n",
    "    'xbg__gamma': [0, 0.1, 1, 10, 100, 1000],\n",
    "    'xbg__reg_alpha': [0, 0.01, 0.1, 1, 10],\n",
    "    'xbg__reg_lambda':[0, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "rs = RandomizedSearchCV(estimator= pipe, param_distributions= params,\n",
    "                       n_iter=300, scoring=ftwo_scorer, n_jobs=-1, cv=3, random_state=12)\n",
    "rand_search = rs.fit(X_train, y_train)\n",
    "rand_model = rand_search.best_estimator_\n",
    "ml, df1 = model_scores('XGBClassifier', rand_model, X_train, y_train, model_list= [], notes = 'Best Estimator from RS')\n",
    "print(rand_search.best_params_)\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearching the winnfer for the final\n",
    "xgb = XGBClassifier(reg_lambda= 1, \n",
    "              reg_alpha= 1,\n",
    "              min_child_weight= 7,\n",
    "              gamma= 0.1,\n",
    "              colsample_bytree= 0.26530612244897955,\n",
    "              tree_method= \"hist\",\n",
    "              scale_pos_weight=283883/24971,\n",
    "              random_state=12)\n",
    "\n",
    "pipe = Pipeline(steps=[('ct', col_transformer),\n",
    "                       ('xbg', xgb)])\n",
    "\n",
    "params = {'xbg__n_estimators': np.linspace(200,300,5,dtype=int),\n",
    "          'xbg__max_depth': [1, 2, 3, 4, 5],\n",
    "          'xbg__eta': np.linspace(0.1,0.2,5)\n",
    "         }\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid= params, scoring=ftwo_scorer, n_jobs=-1, cv=5)\n",
    "\n",
    "g_search = gs.fit(X_train, y_train)\n",
    "gs_model = g_search.best_estimator_\n",
    "ml, df1 = model_scores('XGBClassifier', gs_model, X_train, y_train, model_list= [], notes = 'Best Estimator from GS')\n",
    "print(g_search.best_params_)\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T16:17:50.925387Z",
     "start_time": "2023-08-26T16:17:37.916453Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "xgb = XGBClassifier(reg_lambda= 1, \n",
    "              reg_alpha= 1,\n",
    "              n_estimators= 250,\n",
    "              min_child_weight= 7,\n",
    "              max_depth= 3,\n",
    "              gamma= 0.1,\n",
    "              eta= 0.15,\n",
    "              colsample_bytree= 0.26530612244897955,\n",
    "              tree_method= \"hist\",\n",
    "              scale_pos_weight=283883/24971,\n",
    "              random_state=12)\n",
    "\n",
    "pipe = Pipeline(steps=[('ct', col_transformer),\n",
    "                      ('xgb', xgb)])\n",
    "xgb_model = pipe.fit(X_train, y_train)\n",
    "ml, df1 = model_scores('XGBClassifier', xgb_model, X_train, y_train, model_list= ml, notes= \"f2(weighted)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model\n",
    "I decided to have my final model be the step where `greenbelt` was dropped (index = 8) because the the Adjusted R-Squared was high, the Mean Absolute Error was relatively low, and the Conditional Number didn't seem to improve much as the iteration continued. \n",
    "\n",
    "**Target Variable:** price <br>\n",
    "**Predictor Variables:** sqft_living_norm, waterfront, and 65 different zip codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T16:08:19.879188Z",
     "start_time": "2023-07-03T16:08:19.434986Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This function does the same thing as baseline, but for the final model.\n",
    "final_results, final_df = dm.final_res(df)\n",
    "final_df\n",
    "\n",
    "# I still wonder if 68 features is too many, perhaps this is why the condition \n",
    "# number is still so large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
