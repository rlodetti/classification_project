{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9837a150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T13:29:37.832619Z",
     "start_time": "2023-09-14T13:29:36.433640Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_context(context='talk')\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "\n",
    "df = pd.read_csv('data/Cardiovascular_Diseases_Risk_Prediction_Dataset.csv')\n",
    "y = df['Heart_Disease']\n",
    "X = df.drop('Heart_Disease',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=12, stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1fcf69a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T15:58:22.858062Z",
     "start_time": "2023-09-14T15:58:22.802886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.368645877829987"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8469d52",
   "metadata": {},
   "source": [
    "## Viz 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce88c866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T13:05:44.067063Z",
     "start_time": "2023-09-14T13:05:43.668015Z"
    }
   },
   "outputs": [],
   "source": [
    "def viz_1(df):\n",
    "    # Our target variable is very imbalanced.\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax = sns.countplot(data = df, x= \"Heart_Disease\")\n",
    "    bar_heights = [p.get_height() for p in ax.patches]\n",
    "    ax.text(0, bar_heights[0], '92%', va ='bottom',ha = 'center', size = 'large')\n",
    "    ax.text(1, bar_heights[1], '8%', va ='bottom', ha = 'center', size = 'large')\n",
    "    ax.set(ylim=(0,325000),\n",
    "          title = 'Respondents that reported having Heart Disease',\n",
    "           ylabel = 'Number of Respondents',\n",
    "          xlabel='')\n",
    "    ax.yaxis.set_major_formatter(lambda x, pos: f'{int(x/1000)}K')\n",
    "    plt.savefig('images/viz_1.jpg', bbox_extra_artists=[ax], bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f46a84",
   "metadata": {},
   "source": [
    "## Viz 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ebce31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T12:47:12.074320Z",
     "start_time": "2023-09-14T12:47:07.783529Z"
    }
   },
   "outputs": [],
   "source": [
    "def viz_2(df):\n",
    "    categorical = list(df.select_dtypes(object).columns)\n",
    "    for cat in categorical:\n",
    "        resp = df[cat].value_counts().index\n",
    "        nn = ((df[cat]==resp[0]) & (df['Heart_Disease']=='No')).sum()/(df[cat]==resp[0]).sum()\n",
    "        ny = ((df[cat]==resp[0]) & (df['Heart_Disease']=='Yes')).sum()/(df[cat]==resp[0]).sum()\n",
    "        yn = ((df[cat]==resp[1]) & (df['Heart_Disease']=='No')).sum()/(df[cat]==resp[1]).sum()\n",
    "        yy = ((df[cat]==resp[1]) & (df['Heart_Disease']=='Yes')).sum()/(df[cat]==resp[1]).sum()\n",
    "        num = [nn, yn, ny, yy]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(4,4))\n",
    "        im = ax.imshow([[nn, ny],[yn,yy]],cmap='Blues')\n",
    "        for i,j in enumerate(num):\n",
    "            text = str(round(j*100,2))+'%'\n",
    "            ax.text(i//2, i%2, text,ha=\"center\", va=\"center\", color=\"tab:orange\", weight=\"bold\")\n",
    "        ax.set(xticks= [0,1],\n",
    "               xticklabels= ['No','Yes'],\n",
    "               xlabel = 'Heart Condition',\n",
    "               yticks= [0,1],\n",
    "               yticklabels= [resp[0], resp[1]],\n",
    "               ylabel = cat\n",
    "              )\n",
    "        plt.savefig('images/viz_2.jpg', bbox_extra_artists=[ax], bbox_inches='tight')\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80688ae4",
   "metadata": {},
   "source": [
    "## Helper code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf23ca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T13:25:10.883477Z",
     "start_time": "2023-09-14T13:25:10.883446Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_scores(model, X, y, model_list= [], cv= 5, model_name = ''):\n",
    "    if cv>1:\n",
    "        skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=12)\n",
    "        scoring = {'f2': make_scorer(fbeta_score, beta=2),\n",
    "                   'accuracy':'accuracy',\n",
    "                   'precision': 'precision',\n",
    "                   'recall': 'recall',\n",
    "                   'roc_auc':'roc_auc'}\n",
    "        scores = cross_validate(model,\n",
    "                               X,\n",
    "                               y,\n",
    "                               scoring = scoring,\n",
    "                               cv=skf,\n",
    "                               n_jobs=-1)\n",
    "        f2 = round(scores['test_f2'].mean(),4)*100\n",
    "        accuracy = round(scores['test_accuracy'].mean(),4)*100\n",
    "        precision = round(scores['test_precision'].mean(),4)*100\n",
    "        recall = round(scores['test_recall'].mean(),4)*100\n",
    "        roc_auc = round(scores['test_roc_auc'].mean(),4)*100\n",
    "    else:\n",
    "        y_preds = model.predict(X)\n",
    "        f2 = round(fbeta_score(y,y_preds,beta=2),4)*100\n",
    "        recall = round(recall_score(y,y_preds),4)*100\n",
    "        accuracy = round(accuracy_score(y,y_preds),4)*100\n",
    "        precision = round(precision_score(y,y_preds, zero_division=0.0),4)*100\n",
    "        roc_auc = round(roc_auc_score(y,y_preds),4)*100\n",
    "    model_list.append([model_name, f2, accuracy, precision, recall, roc_auc])\n",
    "    df = pd.DataFrame(model_list, columns=['name', 'f2', 'accuracy', 'precision', 'recall',  'roc_auc'])\n",
    "    return model_list, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbb456",
   "metadata": {},
   "source": [
    "# Randomize the Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f95ea242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T13:30:36.730597Z",
     "start_time": "2023-09-14T13:30:36.725481Z"
    }
   },
   "outputs": [],
   "source": [
    "def rs_pickles():    \n",
    "    with open('pickles/rs_model.pkl', 'rb') as f:\n",
    "        rs_model = joblib.load(f)\n",
    "    with open('pickles/rand_search.pkl', 'rb') as g:\n",
    "        rand_search = pickle.load(g)\n",
    "    with open('pickles/rs_params.pkl', 'rb') as h:\n",
    "        rs_params = pickle.load(h)\n",
    "    return rs_model, rand_search, rs_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "472d2f66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T13:33:03.844702Z",
     "start_time": "2023-09-14T13:33:03.838819Z"
    }
   },
   "outputs": [],
   "source": [
    "def gs_pickles():    \n",
    "    with open('pickles/gs_model.pkl', 'rb') as f:\n",
    "        gs_model = joblib.load(f)\n",
    "    with open('pickles/g_search.pkl', 'rb') as g:\n",
    "        g_search = pickle.load(g)\n",
    "    with open('pickles/gs_params.pkl', 'rb') as h:\n",
    "        gs_params = pickle.load(h)\n",
    "    return gs_model, grid_search, gs_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d0324d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T13:27:43.623638Z",
     "start_time": "2023-09-14T13:27:43.613280Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_search(X_train, y_train):\n",
    "    pipe = Pipeline(steps=[('ct', ct),\n",
    "                           ('xbg', XGBClassifier(random_state=12,tree_method='hist', scale_pos_weight= 283883/24971))])\n",
    "    params = {\n",
    "        'xbg__n_estimators': range(50,1000,50),\n",
    "        'xbg__max_depth': range(1,15),\n",
    "        'xbg__eta': [0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "        'xbg__colsample_bytree': np.linspace(0,1,50),\n",
    "        'xbg__min_child_weight': range(1,10),\n",
    "        'xbg__gamma': [0, 0.1, 1, 10, 100, 1000],\n",
    "        'xbg__reg_alpha': [0, 0.01, 0.1, 1, 10],\n",
    "        'xbg__reg_lambda':[0, 0.01, 0.1, 1, 10]\n",
    "    }\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    rs = RandomizedSearchCV(estimator= pipe, param_distributions= params,\n",
    "                           n_iter=500, scoring=ftwo_scorer, n_jobs=-1, cv=5, random_state=12)\n",
    "    rand_search = rs.fit(X_train, y_train)\n",
    "    rand_model = rand_search.best_estimator_\n",
    "    ml5, df5 = model_scores(rand_model, X_train, y_train, model_list= [], cv= 5, model_name = 'Best Estimator from RS')\n",
    "    return ml5, df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157781ed",
   "metadata": {},
   "source": [
    "# GridSearching the winnfer for the final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438d72ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T13:27:45.539631Z",
     "start_time": "2023-09-14T13:27:45.529711Z"
    }
   },
   "outputs": [],
   "source": [
    "def grid_search(X_train,y_train):\n",
    "    xgb = XGBClassifier(reg_lambda= 10, \n",
    "                  reg_alpha= 0.1,\n",
    "                  min_child_weight= 1,\n",
    "                  gamma= 10,\n",
    "                  colsample_bytree= 0.42857142857142855,\n",
    "                  tree_method= \"hist\",\n",
    "                  scale_pos_weight=283883/24971,\n",
    "                  random_state=12)\n",
    "\n",
    "    pipe = Pipeline(steps=[('ct', ct),\n",
    "                           ('xbg', xgb)])\n",
    "\n",
    "    params = {'xbg__n_estimators': np.linspace(400,800,10,dtype=int),\n",
    "              'xbg__max_depth': [2,3,4,5,6,7],\n",
    "              'xbg__eta': np.linspace(0.1,0.2,10)\n",
    "             }\n",
    "\n",
    "    gs = GridSearchCV(pipe, param_grid= params, scoring=ftwo_scorer, n_jobs=-1, cv=5, verbose= 3)\n",
    "\n",
    "    g_search = gs.fit(X_train, y_train)\n",
    "    gs_model = g_search.best_estimator_\n",
    "    ml5, df5 = model_scores(gs_model, X_train, y_train, model_list= ml5, cv= 5, model_name = 'Best Estimator from GS')\n",
    "    return ml5, df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a2174e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b1953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, fbeta_score, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "sns.set_context(context='notebook')\n",
    "\n",
    "def viz_1(df):\n",
    "    \"\"\"\n",
    "    This function makes a bar graph showing the distribution of respondents with and without a heart condition.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax = sns.countplot(data=df, x=\"Heart_Disease\")\n",
    "    bar_heights = [p.get_height() for p in ax.patches]\n",
    "    ax.text(0, bar_heights[0], '92%', va='bottom', ha='center', size='large')\n",
    "    ax.text(1, bar_heights[1], '8%', va='bottom', ha='center', size='large')\n",
    "    ax.set(ylim=(0, 325000),\n",
    "           title='Respondents that reported having Heart Disease',\n",
    "           ylabel='Number of Respondents',\n",
    "           xlabel='')\n",
    "    ax.yaxis.set_major_formatter(lambda x, pos: f'{int(x/1000)}K')\n",
    "    plt.savefig('images/viz_1.jpg',\n",
    "                bbox_extra_artists=[ax],\n",
    "                bbox_inches='tight')\n",
    "\n",
    "\n",
    "def viz_2(df, categorical):\n",
    "    \"\"\"\n",
    "    This function calculates the rate of each binary variable compared to whether or not the person has a heart condition. It then creates a visual to display the distribution. \n",
    "    \"\"\"\n",
    "    for cat in categorical:\n",
    "        resp = df[cat].value_counts().index\n",
    "        nn = (\n",
    "            (df[cat] == resp[0]) &\n",
    "            (df['Heart_Disease'] == 'No')).sum() / (df[cat] == resp[0]).sum()\n",
    "        ny = (\n",
    "            (df[cat] == resp[0]) &\n",
    "            (df['Heart_Disease'] == 'Yes')).sum() / (df[cat] == resp[0]).sum()\n",
    "        yn = (\n",
    "            (df[cat] == resp[1]) &\n",
    "            (df['Heart_Disease'] == 'No')).sum() / (df[cat] == resp[1]).sum()\n",
    "        yy = (\n",
    "            (df[cat] == resp[1]) &\n",
    "            (df['Heart_Disease'] == 'Yes')).sum() / (df[cat] == resp[1]).sum()\n",
    "        num = [nn, yn, ny, yy]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        im = ax.imshow([[nn, ny], [yn, yy]], cmap='Blues')\n",
    "        for i, j in enumerate(num):\n",
    "            text = str(round(j * 100, 2)) + '%'\n",
    "            ax.text(i // 2,\n",
    "                    i % 2,\n",
    "                    text,\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    color=\"tab:orange\",\n",
    "                    weight=\"bold\")\n",
    "        ax.set(xticks=[0, 1],\n",
    "               xticklabels=['No', 'Yes'],\n",
    "               xlabel='Heart Condition',\n",
    "               yticks=[0, 1],\n",
    "               yticklabels=[resp[0], resp[1]],\n",
    "               ylabel=cat)\n",
    "        plt.savefig('images/viz_2.jpg',\n",
    "                    bbox_extra_artists=[ax],\n",
    "                    bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def model_scores(model, X, y, model_list=[], cv=5, model_name=''):\n",
    "    \"\"\"\n",
    "    This is a helper function which takes in a fitted estimator, and cross validates it, calculating the f2-score, accuracy, recall, and roc_auc score. It outputs the summary as a dataframe. It also outputs a list in the case that the table builds on itself. \n",
    "    \"\"\"\n",
    "    if cv > 1:\n",
    "        skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=12)\n",
    "        scoring = {\n",
    "            'f2': make_scorer(fbeta_score, beta=2),\n",
    "            'accuracy': 'accuracy',\n",
    "            'precision': make_scorer(precision_score, zero_division=0.0),\n",
    "            'recall': 'recall',\n",
    "            'roc_auc': 'roc_auc'\n",
    "        }\n",
    "        scores = cross_validate(model,\n",
    "                                X,\n",
    "                                y,\n",
    "                                scoring=scoring,\n",
    "                                cv=skf,\n",
    "                                n_jobs=-1)\n",
    "        f2 = round(scores['test_f2'].mean(), 4) * 100\n",
    "        accuracy = round(scores['test_accuracy'].mean(), 4) * 100\n",
    "        precision = round(scores['test_precision'].mean(), 4) * 100\n",
    "        recall = round(scores['test_recall'].mean(), 4) * 100\n",
    "        roc_auc = round(scores['test_roc_auc'].mean(), 4) * 100\n",
    "    else:\n",
    "        y_preds = model.predict(X)\n",
    "        f2 = round(fbeta_score(y, y_preds, beta=2), 4) * 100\n",
    "        recall = round(recall_score(y, y_preds), 4) * 100\n",
    "        accuracy = round(accuracy_score(y, y_preds), 4) * 100\n",
    "        precision = round(precision_score(y, y_preds, zero_division=0.0),\n",
    "                          4) * 100\n",
    "        roc_auc = round(roc_auc_score(y, y_preds), 4) * 100\n",
    "    model_list.append([model_name, f2, accuracy, precision, recall, roc_auc])\n",
    "    df = pd.DataFrame(\n",
    "        model_list,\n",
    "        columns=['name', 'f2', 'accuracy', 'precision', 'recall', 'roc_auc'])\n",
    "    return model_list, df\n",
    "\n",
    "\n",
    "def random_search(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Warning: This may take a long time to run depening on cpu resources.\n",
    "    This function runs a RandomizedSearchCV through our model's pipeline. It outputs the the scores as a list and data frame.     \n",
    "    \"\"\"\n",
    "    pipe = Pipeline(steps=[('ct', ct),\n",
    "                           ('xbg',\n",
    "                            XGBClassifier(random_state=12,\n",
    "                                          tree_method='hist',\n",
    "                                          scale_pos_weight=283883 / 24971))])\n",
    "    params = {\n",
    "        'xbg__n_estimators': range(50, 1000, 50),\n",
    "        'xbg__max_depth': range(1, 15),\n",
    "        'xbg__eta': [0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "        'xbg__colsample_bytree': np.linspace(0, 1, 50),\n",
    "        'xbg__min_child_weight': range(1, 10),\n",
    "        'xbg__gamma': [0, 0.1, 1, 10, 100, 1000],\n",
    "        'xbg__reg_alpha': [0, 0.01, 0.1, 1, 10],\n",
    "        'xbg__reg_lambda': [0, 0.01, 0.1, 1, 10]\n",
    "    }\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    rs = RandomizedSearchCV(estimator=pipe,\n",
    "                            param_distributions=params,\n",
    "                            n_iter=500,\n",
    "                            scoring=ftwo_scorer,\n",
    "                            n_jobs=-1,\n",
    "                            cv=5,\n",
    "                            random_state=12)\n",
    "    rand_search = rs.fit(X_train, y_train)\n",
    "    rand_model = rand_search.best_estimator_\n",
    "    ml5, df5 = model_scores(rand_model,\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            model_list=[],\n",
    "                            cv=5,\n",
    "                            model_name='Best Estimator from RS')\n",
    "    return ml5, df5\n",
    "\n",
    "\n",
    "def grid_search(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Warning: This may take a long time to run depening on cpu resource\n",
    "    This function runs a GridSearchCV on our pipeline looking for the optimal estimator. It outputs the scores as a list and dataframe.\n",
    "    \"\"\"\n",
    "    xgb = XGBClassifier(reg_lambda=10,\n",
    "                        reg_alpha=0.1,\n",
    "                        min_child_weight=1,\n",
    "                        gamma=10,\n",
    "                        colsample_bytree=0.42857142857142855,\n",
    "                        tree_method=\"hist\",\n",
    "                        scale_pos_weight=283883 / 24971,\n",
    "                        random_state=12)\n",
    "\n",
    "    pipe = Pipeline(steps=[('ct', ct), ('xbg', xgb)])\n",
    "\n",
    "    params = {\n",
    "        'xbg__n_estimators': np.linspace(400, 800, 10, dtype=int),\n",
    "        'xbg__max_depth': [2, 3, 4, 5, 6, 7],\n",
    "        'xbg__eta': np.linspace(0.1, 0.2, 10)\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(pipe,\n",
    "                      param_grid=params,\n",
    "                      scoring=ftwo_scorer,\n",
    "                      n_jobs=-1,\n",
    "                      cv=5,\n",
    "                      verbose=3)\n",
    "\n",
    "    g_search = gs.fit(X_train, y_train)\n",
    "    gs_model = g_search.best_estimator_\n",
    "    ml5, df5 = model_scores(gs_model,\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            model_list=ml5,\n",
    "                            cv=5,\n",
    "                            model_name='Best Estimator from GS')\n",
    "    return ml5, df5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
